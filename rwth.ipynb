{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGCGr5GsYsjh",
        "outputId": "5584159d-cc8f-4d09-d750-f2616f1edbc3"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/sign-language-processing/datasets.git -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U32NXn0wYoP6"
      },
      "source": [
        "## Dataset download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bR3ET68zYoP9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "# import sign_language_datasets.datasets\n",
        "from sign_language_datasets.utils.torch_dataset import TFDSTorchDataset\n",
        "from sign_language_datasets.datasets.config import SignDatasetConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zqqm0eD3cD-G"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not running on Google Colab\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "\tfrom google.colab import drive\n",
        "\n",
        "\tIN_COLAB = True\n",
        "\tprint(\"Running on Google Colab\")\n",
        "\tdrive.mount('/content/drive', force_remount=True)\n",
        "except:\n",
        "\tIN_COLAB = False\n",
        "\tprint(\"Not running on Google Colab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RcUF3vxZYoP_"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \".\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "i4O14ovVYoP_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Using custom data configuration rwth_phoenix2014_t_poses\n",
            "WARNING:absl:You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.\n",
            "WARNING:absl:You use TensorFlow DType <dtype: 'int32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to int32.\n"
          ]
        }
      ],
      "source": [
        "config = SignDatasetConfig(name=\"rwth_phoenix2014_t_poses\", version=\"3.0.0\", include_video=False, include_pose=\"holistic\")\n",
        "rwth_phoenix2014_t = tfds.load(name='rwth_phoenix2014_t', builder_kwargs=dict(config=config), data_dir=DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8BAXZsLtYoQA"
      },
      "outputs": [],
      "source": [
        "train_dataset = TFDSTorchDataset(rwth_phoenix2014_t[\"train\"])\n",
        "test_dataset = TFDSTorchDataset(rwth_phoenix2014_t[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c1d4PlXWYoQA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['gloss', 'id', 'pose', 'signer', 'text'])\n",
            "Pose shape: torch.Size([47, 1, 543, 3])\n",
            "Text: guten abend liebe zuschauer\n",
            "\n",
            "dict_keys(['gloss', 'id', 'pose', 'signer', 'text'])\n",
            "Pose shape: torch.Size([56, 1, 543, 3])\n",
            "Text: im bergland fällt zunehmend schnee\n",
            "\n",
            "dict_keys(['gloss', 'id', 'pose', 'signer', 'text'])\n",
            "Pose shape: torch.Size([70, 1, 543, 3])\n",
            "Text: und der wind weht auch noch kräftig aus west bis nordwest\n",
            "\n",
            "dict_keys(['gloss', 'id', 'pose', 'signer', 'text'])\n",
            "Pose shape: torch.Size([99, 1, 543, 3])\n",
            "Text: die aussichten von montag bis mittwoch ändert sich das wetter kaum\n",
            "\n",
            "dict_keys(['gloss', 'id', 'pose', 'signer', 'text'])\n",
            "Pose shape: torch.Size([123, 1, 543, 3])\n",
            "Text: über dem bergland können sich einzelne quellwolken zeigen in küstennähe gibt es auch mal dichtere wolken\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "\n",
        "\n",
        "for datum in itertools.islice(train_dataset, 0, 5):\n",
        "\tprint((datum.keys()))\n",
        "\tprint(f\"Pose shape: {datum['pose']['data'].shape}\")\n",
        "\tprint(f\"Text: {datum['text'].decode('utf-8')}\")\n",
        "\tprint()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-K1iWHgYoQB"
      },
      "source": [
        "## Dataset analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vM_qq128YoQB"
      },
      "outputs": [],
      "source": [
        "# src_lenghts = []\n",
        "# texts = []\n",
        "\n",
        "# for datum in rwth_phoenix2014_t[\"train\"]:\n",
        "# \tsrc_lenghts.append(datum['pose']['data'].shape[0])\n",
        "# \ttexts.append(datum['text'].numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK5Y_TkwYoQB"
      },
      "source": [
        "### Frames analysis for padding and truncation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ltZo3Sw5YoQC"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "\n",
        "# src_lengths_df = pd.Series(src_lenghts)\n",
        "# src_lengths_df.describe(percentiles=[.75, .9, .95, .99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tQej-Lo5YoQC"
      },
      "outputs": [],
      "source": [
        "# src_lengths_df.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48qWRik4YoQC"
      },
      "source": [
        "### Text tokenization and analysis for padding and truncation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "E7M8enEwYoQC"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "TEXT_MODEL = \"google-bert/bert-base-german-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7LY_zdI9RaX1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOS_IDX: 3, EOS_IDX: 4, PAD_IDX: 0\n"
          ]
        }
      ],
      "source": [
        "BOS_IDX = tokenizer.cls_token_id if tokenizer.cls_token_id is not None else -1\n",
        "EOS_IDX = tokenizer.sep_token_id if tokenizer.sep_token_id is not None else -1\n",
        "PAD_IDX = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else -1\n",
        "\n",
        "print(f\"BOS_IDX: {BOS_IDX}, EOS_IDX: {EOS_IDX}, PAD_IDX: {PAD_IDX}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V_OQsn4lYoQC"
      },
      "outputs": [],
      "source": [
        "# tokenized_sequences = tokenizer(texts, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kSCWs0VOYoQC"
      },
      "outputs": [],
      "source": [
        "# tokens_length = [len(tokens) for tokens in tokenized_sequences['input_ids']]\n",
        "# print(max(tokens_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2hvQBgYrYoQD"
      },
      "outputs": [],
      "source": [
        "# print(texts[0])\n",
        "# print(tokenized_sequences[0].ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLJDnSFUYoQD"
      },
      "source": [
        "## Preprocessing and dataloader generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fomPDN0QYoQD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.utils.data as utils\n",
        "\n",
        "\n",
        "MAX_FRAMES = 259\n",
        "MAX_TOKENS = 150\n",
        "BATCH_SIZE = 4\n",
        "\n",
        "def flatten_keypoints(datum: Tensor):\n",
        "\t'''\n",
        "\t\tReshape the pose of datum only keeping the first dimension S (sequence lenght) and flattening the number of keypoints K and their dimensions D.\n",
        "\t\tArgs:\n",
        "\t\t\tdatum: Tensor of shape (S, D, K)\n",
        "\t\tReturns:\n",
        "\t\t\tTensor of shape (frames, D * K)\n",
        "\t'''\n",
        "\treturn datum.view(datum.size(0), -1)\n",
        "\n",
        "def pad_truncate_src(datum: Tensor, max_len: int):\n",
        "\t'''Pad the pose to max_len or truncate it'''\n",
        "\tif datum.size(0) < max_len:\n",
        "\t\treturn torch.cat([datum, torch.zeros(max_len - datum.size(0), datum.size(1))])\n",
        "\telse:\n",
        "\t\treturn datum[:max_len]\n",
        "\n",
        "def collate_fn(batch):\n",
        "\tsrc = [item['pose']['data'] for item in batch]\n",
        "\tsrc = torch.stack([pad_truncate_src(flatten_keypoints(datum), MAX_FRAMES) for datum in src])\n",
        "\ttgt = [str(item['text'].decode('utf-8')) for item in batch]\n",
        "\ttgt = tokenizer(tgt, padding='max_length', max_length=MAX_TOKENS, return_tensors='pt').input_ids\n",
        "\treturn src, tgt\n",
        "\n",
        "train_loader = utils.DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "test_loader = utils.DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ueFV0vG-h4ze"
      },
      "outputs": [],
      "source": [
        "# for src, tgt in train_loader:\n",
        "#   print(src.shape)\n",
        "#   print(tgt.shape)\n",
        "#   break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAr2B2UWYoQD"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDR0rGzsYoQD"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cRabvZjw3_HI"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "\t!pip install lightning -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jsbnlFGSYoQD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(size: int, device: torch.device):\n",
        "    '''\n",
        "        Generates triangular (size, size) mask for the transformer model.\n",
        "    '''\n",
        "    mask = (torch.triu(torch.ones((size, size))) == 1).transpose(0, 1).to(device)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_target_mask(tgt: Tensor, pad_idx: int, device: torch.device):\n",
        "    '''\n",
        "        Create target mask and padding mask for the transformer model.\n",
        "        Args:\n",
        "            tgt: (N, T) where N is the batch size and T is the target sequence length\n",
        "            pad_idx: padding index\n",
        "            device: torch device\n",
        "        Returns:\n",
        "            tgt_mask: (T, T), so to evaluate the i-th token, we can only look at the first i tokens, for all i's\n",
        "            tgt_padding_mask: (N, T), for masking pad tokens\n",
        "    '''\n",
        "    tgt_seq_len = tgt.shape[1]\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)\n",
        "    tgt_padding_mask = (tgt == pad_idx)\n",
        "    return tgt_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "NEcHqBS9YoQD"
      },
      "outputs": [],
      "source": [
        "from torch import Tensor, nn\n",
        "from torch.nn.functional import relu\n",
        "\n",
        "\n",
        "class KeypointsEmbedding(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                in_features: int,\n",
        "                keys_emb_size: int = 128,\n",
        "                kernel_size: int = 5,\n",
        "                out_channels: int = 64,\n",
        "                ):\n",
        "        super(KeypointsEmbedding, self).__init__()\n",
        "\n",
        "        self.fc = nn.Linear(in_features=in_features, out_features=keys_emb_size)\n",
        "        self.conv1d = nn.Conv1d(in_channels=keys_emb_size, out_channels=out_channels, kernel_size=kernel_size)\n",
        "\n",
        "    def forward(self, src_batch: Tensor):\n",
        "        '''\n",
        "            Applies a fully connected layer to each frame of the sequence and then a 1d convolution over the sequence.\n",
        "            Args:\n",
        "                src_batch: (N, S, E)\n",
        "            Returns:\n",
        "                Embedding tensor of shape (N, S - kernel_size + 1, out_channels)\n",
        "        '''\n",
        "        # Flatten S and N dims and apply fc frame by frame\n",
        "        n, s, e = src_batch.shape\n",
        "        src_batch = src_batch.view(n*s ,-1)\n",
        "        src_emb = relu(self.fc(src_batch)).view(n, s, -1)\n",
        "        # Apply 1d convolution over S dim\n",
        "        src_emb = src_emb.permute(0, 2, 1)\n",
        "        src_emb = self.conv1d(src_emb).permute(0, 2, 1)\n",
        "        return src_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "KK31oNMxYoQD"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(1, max_len, d_model)\n",
        "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
        "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        '''\n",
        "        Apply positional encoding to the input tensor.\n",
        "        Args:\n",
        "            x: (N, S, E)\n",
        "        Returns:\n",
        "            Tensor of shape (N, S, E)\n",
        "        '''\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AfZ_bIORYoQE"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from torch import nn, Tensor\n",
        "\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    '''Code taken from https://pytorch.org/tutorials/beginner/translation_transformer.html'''\n",
        "\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        '''\n",
        "            Applies token embedding to the target tensor.\n",
        "            Args:\n",
        "                tokens: (N, T)\n",
        "            Returns:\n",
        "                Tensor of shape (N, T, E)\n",
        "        '''\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gXnSvmFREEJu"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoModel\n",
        "\n",
        "# bert_german = AutoModel.from_pretrained(TEXT_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "4Ktl6PWcYoQE"
      },
      "outputs": [],
      "source": [
        "from torch import Tensor, nn\n",
        "\n",
        "\n",
        "class KeypointsTransformer(nn.Module):\n",
        "    '''\n",
        "        Transformer model for sign language translation. It uses a 1D convolutional layer to embed the keypoints and a transformer to translate the sequence.\n",
        "        S refers to the source sequence length, T to the target sequence length, N to the batch size, and E is the features number.\n",
        "    '''\n",
        "\n",
        "    def __init__(self,\n",
        "                src_max_len: int,\n",
        "                tgt_max_len: int,\n",
        "                in_features: int,\n",
        "                tgt_vocab_size: int,\n",
        "                d_model: int = 512,\n",
        "                kernel_size: int = 5,\n",
        "                keys_emb_size: int = 128,\n",
        "                dropout: float = 0.1\n",
        "                ):\n",
        "        '''\n",
        "            Args:\n",
        "                src_max_len: max length of the source sequence\n",
        "                tgt_max_len: max length of the target sequence\n",
        "                in_features: number of features of the input (amount of keypoints * amount of coordinates)\n",
        "                tgt_vocab_size: size of the target vocabulary\n",
        "                d_model: number of dimensions of the encoding vectors (default=64). Must be even so the positional encoding works.\n",
        "                kernel_size: the size of the 1D convolution window (default=5)\n",
        "                keys_initial_emb_size: the size of the keys embedding (default=128)\n",
        "        '''\n",
        "        super(KeypointsTransformer, self).__init__()\n",
        "\n",
        "        self.keys_emb = KeypointsEmbedding(in_features=in_features, keys_emb_size=keys_emb_size, kernel_size=kernel_size, out_channels=d_model)\n",
        "        self.src_pe = PositionalEncoding(d_model=d_model, max_len=src_max_len - kernel_size + 1)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, d_model)\n",
        "        self.tgt_pe = PositionalEncoding(d_model=d_model, max_len=tgt_max_len)\n",
        "        self.transformer = nn.Transformer(d_model=d_model, dropout=dropout, batch_first=True)\n",
        "        self.generator = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                tgt: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor\n",
        "    ):\n",
        "        '''\n",
        "            Forward pass of the model.\n",
        "            Args:\n",
        "                src: (N, S, E)\n",
        "                tgt: (N, T, E)\n",
        "                tgt_mask: (T, T)\n",
        "                tgt_padding_mask: (N, T)\n",
        "            Returns:\n",
        "                Tensor of shape (N, T, tgt_vocab_size)\n",
        "        '''\n",
        "        src_emb = self.keys_emb(src)\n",
        "        src_emb = self.src_pe(src_emb)\n",
        "        tgt_emb = self.tgt_pe(self.tgt_tok_emb(tgt))\n",
        "        # src_mask and src_key_padding_mask are set to none as we use the whole input at every timestep\n",
        "        outs = self.transformer(\n",
        "            src = src_emb,\n",
        "            tgt = tgt_emb,\n",
        "            src_mask = None,\n",
        "            tgt_mask = tgt_mask,\n",
        "            src_key_padding_mask = None,\n",
        "            tgt_key_padding_mask = tgt_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor):\n",
        "        src_emb = self.src_pe(self.keys_emb(src))\n",
        "        return self.transformer.encoder(src_emb, None)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.tgt_pe(self.tgt_tok_emb(tgt)), memory, tgt_mask)\n",
        "\n",
        "KEYS_EMB_SIZE = 32\n",
        "D_MODEL = 32\n",
        "KERNEL_SIZE = 10\n",
        "DROPOUT = 0.1\n",
        "\n",
        "NUM_KEYPOINTS = 543\n",
        "IN_FEATURES = NUM_KEYPOINTS*3\n",
        "\n",
        "model = KeypointsTransformer(\n",
        "    src_max_len=MAX_FRAMES,\n",
        "    tgt_max_len=MAX_TOKENS,\n",
        "    in_features=IN_FEATURES,\n",
        "    tgt_vocab_size=tokenizer.vocab_size,\n",
        "    d_model=D_MODEL,\n",
        "    kernel_size=KERNEL_SIZE,\n",
        "    keys_emb_size=KEYS_EMB_SIZE,\n",
        "    dropout=DROPOUT\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NtRybihvA-cu"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "\t!pip install modelsummary -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "o4OiNKV838b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 259, 1629]) torch.Size([32, 150]) torch.Size([150, 150]) torch.Size([32, 150])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (259) must match the size of tensor b (250) at non-singleton dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[34], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(src\u001b[38;5;241m.\u001b[39mshape, tgt\u001b[38;5;241m.\u001b[39mshape, tgt_mask\u001b[38;5;241m.\u001b[39mshape, tgt_padding_mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 13\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/modelsummary/modelsummary.py:70\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, batch_size, show_input, show_hierarchical, *inputs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# register hook\u001b[39;00m\n\u001b[1;32m     69\u001b[0m model\u001b[38;5;241m.\u001b[39mapply(register_hook)\n\u001b[0;32m---> 70\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/torch/nn/modules/module.py:1536\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1534\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1535\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1539\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[33], line 57\u001b[0m, in \u001b[0;36mKeypointsTransformer.forward\u001b[0;34m(self, src, tgt, tgt_mask, tgt_padding_mask)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    Forward pass of the model.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m        Tensor of shape (N, T, tgt_vocab_size)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     56\u001b[0m src_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_emb(src)\n\u001b[0;32m---> 57\u001b[0m src_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_pe\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_emb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m tgt_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgt_pe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgt_tok_emb(tgt))\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# src_mask and src_key_padding_mask are set to none as we use the whole input at every timestep\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/torch/nn/modules/module.py:1577\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1574\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1575\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1577\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1579\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1580\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1581\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1582\u001b[0m     ):\n\u001b[1;32m   1583\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[31], line 27\u001b[0m, in \u001b[0;36mPositionalEncoding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Apply positional encoding to the input tensor.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m        Tensor of shape (N, S, E)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpe\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (259) must match the size of tensor b (250) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "from modelsummary import summary\n",
        "\n",
        "\n",
        "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else (\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "\n",
        "src = torch.randn(D_MODEL, MAX_FRAMES, IN_FEATURES).to(DEVICE)\n",
        "tgt = torch.randint(0, tokenizer.vocab_size, (D_MODEL, MAX_TOKENS)).to(DEVICE)\n",
        "tgt_mask = torch.zeros(MAX_TOKENS, MAX_TOKENS).to(DEVICE)\n",
        "tgt_padding_mask = torch.randint(0, 2, (D_MODEL, MAX_TOKENS)).bool().to(DEVICE)\n",
        "print(src.shape, tgt.shape, tgt_mask.shape, tgt_padding_mask.shape)\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "summary(model, src, tgt, tgt_mask, tgt_padding_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUdekzqZXbkG"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DS46dluKtnOd"
      },
      "outputs": [],
      "source": [
        "if IN_COLAB:\n",
        "\t!pip install wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_he4uDwy7Dwu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n"
          ]
        }
      ],
      "source": [
        "from torch import Tensor\n",
        "from torch.optim import Adam\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torchmetrics import Accuracy\n",
        "import lightning as L\n",
        "\n",
        "\n",
        "class LKeypointsTransformer(L.LightningModule):\n",
        "\n",
        "    def __init__(self, model: KeypointsTransformer, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.loss_fn = cross_entropy\n",
        "        self.accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes, ignore_index=PAD_IDX)\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "    def forward(self, src: Tensor, tgt: Tensor, tgt_mask: Tensor, tgt_padding_mask: Tensor):\n",
        "        return self.model(src, tgt, tgt_mask, tgt_padding_mask)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer\n",
        "\n",
        "    def run_on_batch(self, batch):\n",
        "        src, tgt = batch\n",
        "        # tgt_input and tgt_ouptut are displaced by one position, so tgt_input[i] is the input to the model and tgt_output[i] is the expected output\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        tgt_mask, tgt_padding_mask = create_target_mask(tgt_input, PAD_IDX, DEVICE)\n",
        "        logits = self.model(src, tgt_input, tgt_mask, tgt_padding_mask)\n",
        "        tgt_output = tgt[:, 1:]\n",
        "        loss = self.loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_output.reshape(-1), ignore_index=PAD_IDX)\n",
        "        accuracy = self.accuracy(logits.reshape(-1, logits.shape[-1]), tgt_output.reshape(-1))\n",
        "        return loss, accuracy\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, accuracy = self.run_on_batch(batch)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        self.log(\"train_accuracy\", accuracy)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, accuracy = self.run_on_batch(batch)\n",
        "        self.log(\"val_loss\", loss)\n",
        "        self.log(\"val_accuracy\", accuracy)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss, accuracy = self.run_on_batch(batch)\n",
        "        self.log(\"test_loss\", loss)\n",
        "        self.log(\"test_accuracy\", accuracy)\n",
        "        return loss, accuracy\n",
        "\n",
        "    # function to generate output sequence using greedy algorithm\n",
        "    def greedy_translate(self, src):\n",
        "        memory = self.model.encode(src)\n",
        "        ys = torch.ones(1, 1).fill_(BOS_IDX).to(DEVICE)\n",
        "        for i in range(MAX_TOKENS-1):\n",
        "            tgt_mask = generate_square_subsequent_mask(ys.size(1), DEVICE)\n",
        "            out = model.decode(ys, memory, tgt_mask)\n",
        "            prob = model.generator(out[:, -1])\n",
        "            _, next_word = torch.max(prob, dim=1)\n",
        "            next_word = next_word.item()\n",
        "            # print(next_word)\n",
        "            ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
        "            if next_word == EOS_IDX:\n",
        "                break\n",
        "        return tokenizer.decode([int(x) for x in ys[0].tolist()], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "l_model = LKeypointsTransformer(model, tokenizer.vocab_size)\n",
        "# CHKP = \"rwth/e3lz0h2y/checkpoints/epoch=4-step=2220.ckpt\"\n",
        "# l_model = LKeypointsTransformer.load_from_checkpoint(CHKP, model=model, num_classes=tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Av5r8Xx5YoQE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpedroodb\u001b[0m (\u001b[33mlidiaa\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem at: /opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/wandb/sdk/wandb_init.py 854 getcaller\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloggers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WandbLogger\n\u001b[1;32m      6\u001b[0m wandb_logger \u001b[38;5;241m=\u001b[39m WandbLogger(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrwth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mwandb_logger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m      8\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBATCH_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: BATCH_SIZE,\n\u001b[1;32m      9\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEVICE\u001b[39m\u001b[38;5;124m\"\u001b[39m: DEVICE,\n\u001b[1;32m     10\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAX_FRAMES\u001b[39m\u001b[38;5;124m\"\u001b[39m: MAX_FRAMES,\n\u001b[1;32m     11\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAX_TOKENS\u001b[39m\u001b[38;5;124m\"\u001b[39m: MAX_TOKENS,\n\u001b[1;32m     12\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEXT_MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m: TEXT_MODEL,\n\u001b[1;32m     13\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKEYS_EMB_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: KEYS_EMB_SIZE,\n\u001b[1;32m     14\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD_MODEL\u001b[39m\u001b[38;5;124m\"\u001b[39m: D_MODEL,\n\u001b[1;32m     15\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKERNEL_SIZE\u001b[39m\u001b[38;5;124m\"\u001b[39m: KERNEL_SIZE,\n\u001b[1;32m     16\u001b[0m \t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDROPOUT\u001b[39m\u001b[38;5;124m\"\u001b[39m: DROPOUT,\n\u001b[1;32m     17\u001b[0m })\n\u001b[1;32m     19\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     20\u001b[0m     logger\u001b[38;5;241m=\u001b[39mwandb_logger,\n\u001b[1;32m     21\u001b[0m     default_root_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \t\t),],\n\u001b[1;32m     31\u001b[0m )\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/lightning/fabric/loggers/logger.py:118\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank_zero_only\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _DummyExperiment()\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/lightning/pytorch/loggers/wandb.py:401\u001b[0m, in \u001b[0;36mWandbLogger.experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39m_attach(attach_id)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# create new wandb process\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment \u001b[38;5;241m=\u001b[39m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wandb_init\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# define default x-axis\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment, (Run, RunDisabled)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefine_metric\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     ):\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1199\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1197\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n\u001b[1;32m   1198\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterrupted\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m-> 1199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1201\u001b[0m     error_seen \u001b[38;5;241m=\u001b[39m e\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:1176\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1174\u001b[0m except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:817\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    815\u001b[0m run_start_handle \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mdeliver_run_start(run\u001b[38;5;241m.\u001b[39m_run_obj)\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# TODO: add progress to let user know we are doing something\u001b[39;00m\n\u001b[0;32m--> 817\u001b[0m run_start_result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_start_handle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_start_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    819\u001b[0m     run_start_handle\u001b[38;5;241m.\u001b[39mabandon()\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py:283\u001b[0m, in \u001b[0;36mMailboxHandle.wait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interface\u001b[38;5;241m.\u001b[39m_transport_keepalive_failed():\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MailboxError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransport failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 283\u001b[0m found, abandoned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_slot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_and_clear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m found:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# Always update progress to 100% when done\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on_progress \u001b[38;5;129;01mand\u001b[39;00m progress_handle \u001b[38;5;129;01mand\u001b[39;00m progress_sent:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py:130\u001b[0m, in \u001b[0;36m_MailboxSlot._get_and_clear\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_and_clear\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[pb\u001b[38;5;241m.\u001b[39mResult], \u001b[38;5;28mbool\u001b[39m]:\n\u001b[1;32m    129\u001b[0m     found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m             found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py:126\u001b[0m, in \u001b[0;36m_MailboxSlot._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout: \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/slt_models_tryout/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "\n",
        "\n",
        "wandb_logger = WandbLogger(project=\"rwth\")\n",
        "wandb_logger.experiment.config.update({\n",
        "\t\"BATCH_SIZE\": BATCH_SIZE,\n",
        "\t\"DEVICE\": DEVICE,\n",
        "\t\"MAX_FRAMES\": MAX_FRAMES,\n",
        "\t\"MAX_TOKENS\": MAX_TOKENS,\n",
        "\t\"TEXT_MODEL\": TEXT_MODEL,\n",
        "\t\"KEYS_EMB_SIZE\": KEYS_EMB_SIZE,\n",
        "\t\"D_MODEL\": D_MODEL,\n",
        "\t\"KERNEL_SIZE\": KERNEL_SIZE,\n",
        "\t\"DROPOUT\": DROPOUT,\n",
        "})\n",
        "\n",
        "trainer = L.Trainer(\n",
        "    logger=wandb_logger,\n",
        "    default_root_dir=\"./checkpoint\",\n",
        "    callbacks=[\n",
        "\t\tEarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5),\n",
        "\t\tModelCheckpoint(\n",
        "\t\t\tmonitor='val_loss',\n",
        "\t\t\tdirpath='checkpoints/',\n",
        "\t\t\tfilename='rwth-{epoch:02d}-{step:02d}-{val_loss:.2f}',\n",
        "\t\t\tmode='min',\n",
        "\t\t\tsave_last=True\n",
        "\t\t),],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU8ozZtpRaX4"
      },
      "outputs": [],
      "source": [
        "trainer.fit(\n",
        "    model=l_model,\n",
        "    train_dataloaders=train_loader,\n",
        "    val_dataloaders=test_loader,\n",
        "    # ckpt_path=\"checkpoints/rwth-epoch=00-step=1774-val_loss=5.75.ckpt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ibgAbSqifv1"
      },
      "outputs": [],
      "source": [
        "trainer.test(\n",
        "    model=l_model,\n",
        "\tdataloaders=test_loader,\n",
        "    ckpt_path=\"/content/checkpoints/rwth-epoch=15-step=896-val_loss=2.42.ckpt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swGo1wYgRaX4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torchmetrics.functional.text import bleu_score\n",
        "\n",
        "\n",
        "try:\n",
        "\tresults_df = pd.read_csv(\"results.csv\")\n",
        "\tlast_idx = len(results_df)\n",
        "except:\n",
        "\tresults_df = pd.DataFrame(columns=[\"pred\", \"tgt\", \"bleu_1\", \"bleu_2\", \"bleu_3\", \"bleu_4\"])\n",
        "\tlast_idx = 0\n",
        "\n",
        "results = []\n",
        "for batch_idx, (src, tgt) in enumerate(test_loader):\n",
        "\tsrc = src.to(DEVICE)\n",
        "\tfor i in range(len(src)):\n",
        "\t\tif last_idx > batch_idx * 4 + i:\n",
        "\t\t\tcontinue\n",
        "\t\tprint(f\"Batch {batch_idx}, sample {i}\")\n",
        "\t\t# adds extra dimension representing the batch\n",
        "\t\tsrc_0 = src[i].unsqueeze(0)\n",
        "\t\tl_model = l_model.to(DEVICE)\n",
        "\t\tpred = (l_model.greedy_translate(src_0))\n",
        "\t\ty = tokenizer.decode([int(x) for x in tgt[i].tolist()], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\t\tresults.append((pred, y) + tuple(bleu_score(pred, [y], n_gram=n).item() for n in range(1, 5)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HWS3364RaX-"
      },
      "outputs": [],
      "source": [
        "results_df = pd.concat([results_df, pd.DataFrame(results, columns=[\"pred\", \"tgt\", \"bleu_1\", \"bleu_2\", \"bleu_3\", \"bleu_4\"])])\n",
        "results_df.to_csv(\"results.csv\", index=False)\n",
        "results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIragUlzRaX_"
      },
      "outputs": [],
      "source": [
        "results_df.describe()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
