{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def get_folder_size_gb(folder_path: str) -> float:\n",
    "    return sum(\n",
    "        os.path.getsize(os.path.join(dirpath, filename))\n",
    "        for dirpath, _, filenames in os.walk(folder_path)\n",
    "        for filename in filenames\n",
    "    ) / (1024**3)\n",
    "\n",
    "\n",
    "datasets = json.load(open(\"datasets.json\", \"r\"))\n",
    "for dataset in datasets:\n",
    "    if \"size\" not in dataset:\n",
    "        print(f\"Processing {dataset['id']}\")\n",
    "        dataset[\"size\"] = get_folder_size_gb(dataset[\"path\"])\n",
    "        print(f\"Size: {dataset['size']} GB\")\n",
    "json.dump(datasets, open(\"datasets.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek_sl_dataset</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/GSL</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>indian_sl_dataset</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/ISL</td>\n",
       "      <td>422.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSFB-CONT</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/LSFB-CONT</td>\n",
       "      <td>28.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How2Sign</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/How2Sign</td>\n",
       "      <td>69.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsat</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/lsat</td>\n",
       "      <td>45.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>phoenix14t</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/RWTH_PHOENIX_2014T</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Content4All-SWISSTXT-NEWS</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/Content4All/ANNOTATE...</td>\n",
       "      <td>27.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Content4All-SWISSTXT-WEATHER</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/Content4All/ANNOTATE...</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Content4All-VRT-NEWS</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/Content4All/ANNOTATE...</td>\n",
       "      <td>17.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WMT-SLT23 (part 1)</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/WMT-SLT23</td>\n",
       "      <td>160.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WMT-SLT23 (part 2)</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/WMT-SLT23-2</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WMT-SLT23 (part 3)</td>\n",
       "      <td>/mnt/disk3Tb/slt-datasets/WMT-SLT23-3</td>\n",
       "      <td>303.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  \\\n",
       "0               greek_sl_dataset   \n",
       "1              indian_sl_dataset   \n",
       "2                      LSFB-CONT   \n",
       "3                       How2Sign   \n",
       "4                           lsat   \n",
       "5                     phoenix14t   \n",
       "6      Content4All-SWISSTXT-NEWS   \n",
       "7   Content4All-SWISSTXT-WEATHER   \n",
       "8           Content4All-VRT-NEWS   \n",
       "9             WMT-SLT23 (part 1)   \n",
       "10            WMT-SLT23 (part 2)   \n",
       "11            WMT-SLT23 (part 3)   \n",
       "\n",
       "                                                 path    size  \n",
       "0                       /mnt/disk3Tb/slt-datasets/GSL    5.42  \n",
       "1                       /mnt/disk3Tb/slt-datasets/ISL  422.51  \n",
       "2                 /mnt/disk3Tb/slt-datasets/LSFB-CONT   28.05  \n",
       "3                  /mnt/disk3Tb/slt-datasets/How2Sign   69.47  \n",
       "4                      /mnt/disk3Tb/slt-datasets/lsat   45.59  \n",
       "5        /mnt/disk3Tb/slt-datasets/RWTH_PHOENIX_2014T    5.75  \n",
       "6   /mnt/disk3Tb/slt-datasets/Content4All/ANNOTATE...   27.72  \n",
       "7   /mnt/disk3Tb/slt-datasets/Content4All/ANNOTATE...    2.74  \n",
       "8   /mnt/disk3Tb/slt-datasets/Content4All/ANNOTATE...   17.33  \n",
       "9                 /mnt/disk3Tb/slt-datasets/WMT-SLT23  160.37  \n",
       "10              /mnt/disk3Tb/slt-datasets/WMT-SLT23-2    0.09  \n",
       "11              /mnt/disk3Tb/slt-datasets/WMT-SLT23-3  303.42  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame(datasets)\n",
    "df[\"size\"] = df[\"size\"].round(2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1088.46"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"size\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLTDataset import SLTDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def text_analysis(text_series: pd.Series, freq_lt_thresholds: list[int] = [10]):\n",
    "    sentence_count = text_series.value_counts()\n",
    "    words = [\n",
    "        word\n",
    "        for sentence in map(lambda t: str(t).split(), text_series.to_list())\n",
    "        for word in sentence\n",
    "    ]\n",
    "    word_counts = Counter(words)\n",
    "\n",
    "    output = {\n",
    "        \"num_samples\": len(text_series),\n",
    "        \"unique_sentence_count\": len(sentence_count[sentence_count == 1]),\n",
    "        \"unique_sentence_percentage\": round(\n",
    "            100 * text_series.nunique() / len(text_series), 2\n",
    "        ),\n",
    "        \"vocabulary_size\": len(word_counts),\n",
    "        \"singleton_count\": len(\n",
    "            [word for word, count in word_counts.items() if count == 1]\n",
    "        ),\n",
    "        \"singleton_percentage\": round(\n",
    "            100\n",
    "            * len([word for word, count in word_counts.items() if count == 1])\n",
    "            / len(word_counts),\n",
    "            2,\n",
    "        ),\n",
    "    }\n",
    "    for threshold in freq_lt_thresholds:\n",
    "        output[f\"word_count_lt_{threshold}\"] = len(\n",
    "            [word for word, count in word_counts.items() if count <= threshold]\n",
    "        )\n",
    "        output[f\"word_percentage_lt_{threshold}\"] = round(\n",
    "            100\n",
    "            * len([word for word, count in word_counts.items() if count <= threshold])\n",
    "            / len(word_counts),\n",
    "            2,\n",
    "        )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_analysis = []\n",
    "indices = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Greek Sign Language Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata: {\n",
      "    \"name\": \"The Greek Sign Language (GSL) Dataset\",\n",
      "    \"id\": \"greek_sl_dataset\",\n",
      "    \"url\": \"https://vcl.iti.gr/dataset/gsl/\",\n",
      "    \"download_link\": \"https://drive.google.com/drive/folders/18ruYi9MULMm1KQtUgdIhN0m-XilRhncg\",\n",
      "    \"mirror_link\": \"https://drive.google.com/drive/folders/1EAVE5dxQIKGAL2yB0alvgTlv2t3JKW5v?usp=sharing\",\n",
      "    \"input_language\": \"Greek Sign Language (GSL)\",\n",
      "    \"output_language\": \"greek\",\n",
      "    \"input_types\": [\n",
      "        \"video\",\n",
      "        \"pose\"\n",
      "    ],\n",
      "    \"output_types\": [\n",
      "        \"text\",\n",
      "        \"gloss\"\n",
      "    ]\n",
      "}\n",
      "Loaded annotations at /mnt/disk3Tb/slt-datasets/GSL/annotations.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating files:   0%|          | 0/10290 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating files: 100%|██████████| 10290/10290 [00:00<00:00, 263301.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded correctly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/mnt/disk3Tb/slt-datasets/GSL\"\n",
    "\n",
    "gsl_dataset = SLTDataset(data_dir=DATA_DIR, input_mode=\"pose\", output_mode=\"text\")\n",
    "texts_analysis.append(text_analysis(gsl_dataset.annotations[\"text\"]))\n",
    "indices.append(gsl_dataset.metadata[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata: {\n",
      "    \"name\": \"ISLTranslate\",\n",
      "    \"id\": \"indian_sl_dataset\",\n",
      "    \"url\": \"https://github.com/exploration-lab/isltranslate?tab=readme-ov-file\",\n",
      "    \"download_link\": \"https://1drv.ms/f/s!AuBOJ2hW9GimgblntP72D_agQdokdQ?e=ZbeA6y\",\n",
      "    \"mirror_link\": \"\",\n",
      "    \"input_language\": \"Indian Sign Language (ISL)\",\n",
      "    \"output_language\": \"english\",\n",
      "    \"input_types\": [\n",
      "        \"video\",\n",
      "        \"pose\"\n",
      "    ],\n",
      "    \"output_types\": [\n",
      "        \"text\"\n",
      "    ]\n",
      "}\n",
      "Loaded annotations at /mnt/disk3Tb/slt-datasets/ISL/annotations.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating files: 100%|██████████| 125856/125856 [00:00<00:00, 273270.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/mnt/disk3Tb/slt-datasets/ISL\"\n",
    "\n",
    "isl_dataset = SLTDataset(data_dir=DATA_DIR, input_mode=\"pose\", output_mode=\"text\")\n",
    "texts_analysis.append(text_analysis(isl_dataset.annotations[\"text\"]))\n",
    "indices.append(isl_dataset.metadata[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata: {\n",
      "    \"name\": \"RWTH-PHOENIX-Weather 2014 T: Parallel Corpus of Sign Language Video, Gloss and Translation\",\n",
      "    \"id\": \"rwth_phoenix_weather_2014_t\",\n",
      "    \"url\": \"https://www-i6.informatik.rwth-aachen.de/~koller/RWTH-PHOENIX-2014-T/\",\n",
      "    \"download_link\": \"https://www-i6.informatik.rwth-aachen.de/ftp/pub/rwth-phoenix/2016/phoenix-2014-T.v3.tar.gz\",\n",
      "    \"mirror_link\": \"\",\n",
      "    \"input_language\": \"German Sign Language (GSL)\",\n",
      "    \"output_language\": \"german\",\n",
      "    \"input_types\": [\n",
      "        \"video\",\n",
      "        \"pose\"\n",
      "    ],\n",
      "    \"output_types\": [\n",
      "        \"text\",\n",
      "        \"gloss\"\n",
      "    ]\n",
      "}\n",
      "Loaded annotations at /mnt/disk3Tb/slt-datasets/RWTH_PHOENIX_2014T/annotations.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating files:   0%|          | 0/8257 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating files: 100%|██████████| 8257/8257 [00:00<00:00, 256342.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded correctly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/mnt/disk3Tb/slt-datasets/RWTH_PHOENIX_2014T\"\n",
    "\n",
    "rwth_dataset = SLTDataset(data_dir=DATA_DIR, input_mode=\"pose\", output_mode=\"text\")\n",
    "texts_analysis.append(text_analysis(rwth_dataset.annotations[\"text\"]))\n",
    "indices.append(rwth_dataset.metadata[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata: {\n",
      "    \"name\": \"LSA-T\",\n",
      "    \"id\": \"lsat\",\n",
      "    \"url\": \"https://midusi.github.io/LSA-T/\",\n",
      "    \"download_link\": \"https://midusi.github.io/LSA-T/\",\n",
      "    \"mirror_link\": \"\",\n",
      "    \"input_language\": \"Argentinian Sign Language (LSA)\",\n",
      "    \"output_language\": \"spanish\",\n",
      "    \"input_types\": [\n",
      "        \"video\",\n",
      "        \"pose\"\n",
      "    ],\n",
      "    \"output_types\": [\n",
      "        \"text\"\n",
      "    ]\n",
      "}\n",
      "Loaded annotations at /mnt/disk3Tb/slt-datasets/lsat/annotations.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating files: 100%|██████████| 8459/8459 [00:00<00:00, 275503.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/mnt/disk3Tb/slt-datasets/lsat\"\n",
    "\n",
    "lsat_dataset = SLTDataset(data_dir=DATA_DIR, input_mode=\"pose\", output_mode=\"text\")\n",
    "texts_analysis.append(text_analysis(lsat_dataset.annotations[\"text\"]))\n",
    "indices.append(lsat_dataset.metadata[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_samples</th>\n",
       "      <th>unique_sentence_count</th>\n",
       "      <th>unique_sentence_percentage</th>\n",
       "      <th>vocabulary_size</th>\n",
       "      <th>singleton_count</th>\n",
       "      <th>singleton_percentage</th>\n",
       "      <th>word_count_lt_10</th>\n",
       "      <th>word_percentage_lt_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>greek_sl_dataset</th>\n",
       "      <td>10290</td>\n",
       "      <td>55</td>\n",
       "      <td>3.18</td>\n",
       "      <td>479</td>\n",
       "      <td>22</td>\n",
       "      <td>4.59</td>\n",
       "      <td>33</td>\n",
       "      <td>6.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian_sl_dataset</th>\n",
       "      <td>125856</td>\n",
       "      <td>119008</td>\n",
       "      <td>96.00</td>\n",
       "      <td>75155</td>\n",
       "      <td>37456</td>\n",
       "      <td>49.84</td>\n",
       "      <td>65391</td>\n",
       "      <td>87.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rwth_phoenix_weather_2014_t</th>\n",
       "      <td>8257</td>\n",
       "      <td>7900</td>\n",
       "      <td>96.35</td>\n",
       "      <td>3000</td>\n",
       "      <td>1110</td>\n",
       "      <td>37.00</td>\n",
       "      <td>2176</td>\n",
       "      <td>72.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lsat</th>\n",
       "      <td>8459</td>\n",
       "      <td>7727</td>\n",
       "      <td>94.81</td>\n",
       "      <td>20479</td>\n",
       "      <td>12002</td>\n",
       "      <td>58.61</td>\n",
       "      <td>19156</td>\n",
       "      <td>93.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             num_samples  unique_sentence_count  \\\n",
       "greek_sl_dataset                   10290                     55   \n",
       "indian_sl_dataset                 125856                 119008   \n",
       "rwth_phoenix_weather_2014_t         8257                   7900   \n",
       "lsat                                8459                   7727   \n",
       "\n",
       "                             unique_sentence_percentage  vocabulary_size  \\\n",
       "greek_sl_dataset                                   3.18              479   \n",
       "indian_sl_dataset                                 96.00            75155   \n",
       "rwth_phoenix_weather_2014_t                       96.35             3000   \n",
       "lsat                                              94.81            20479   \n",
       "\n",
       "                             singleton_count  singleton_percentage  \\\n",
       "greek_sl_dataset                          22                  4.59   \n",
       "indian_sl_dataset                      37456                 49.84   \n",
       "rwth_phoenix_weather_2014_t             1110                 37.00   \n",
       "lsat                                   12002                 58.61   \n",
       "\n",
       "                             word_count_lt_10  word_percentage_lt_10  \n",
       "greek_sl_dataset                           33                   6.89  \n",
       "indian_sl_dataset                       65391                  87.01  \n",
       "rwth_phoenix_weather_2014_t              2176                  72.53  \n",
       "lsat                                    19156                  93.54  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(texts_analysis, index=indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slt_datasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
